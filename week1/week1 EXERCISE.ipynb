{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown, update_display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize \n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "#constants\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a technical tutor to a software engineer specializing in\n",
    ".NET, Java and currently studing LLM engineering course taught in Python. \n",
    "You will assist in answering questions, providing code snippets, and explaining concepts\n",
    "related to Python, LLM(s) and data science. Make your answers concise.\n",
    "\"\"\"\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda21e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dacf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_answer(messages = messages, model=MODEL_GPT):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def display_answer_stream(question, model=MODEL_GPT):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    answer = \"\"\n",
    "\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        answer += chunk.choices[0].delta.content or ''\n",
    "        response = answer.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(answer), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(messages, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer_stream(messages, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "response = ollama.chat(MODEL_LLAMA, messages)\n",
    "reply = response['message']['content']\n",
    "display(Markdown(reply))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a585f",
   "metadata": {},
   "source": [
    "# Making this interactive.\n",
    " \n",
    "Enter the input at the top of the Visual Studio Code Window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = input(\"Please enter your question:\")\n",
    "# Update user prompt with the new question\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + my_question\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "display_answer(messages, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25511fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
